# ğŸš€ ETL Sales Pipeline with AWS Glue 5.0

| Language | Idioma |
|----------|--------|
| ğŸ‡ºğŸ‡¸ English | [EspaÃ±ol](#-pipeline-de-procesamiento-de-ventas-con-aws-glue-50) |

---

This project implements an AWS Glue 5.0 ETL job to transform raw sales data stored as CSV files in S3 into clean, structured Parquet files. It applies safe type casting, validation, and the calculation of a derived metric (`total_venta`). Designed as a foundational component for modern analytics pipelines.

## ğŸ§± Stack

- AWS Glue 5.0 (Spark 3.5, Python 3.11)
- Amazon S3
- PySpark
- Parquet output
- Compatible with Lambda, Airflow, Redshift

## âš™ï¸ ETL Logic

- **Input**: `s3://data-cgarridolizana/raw/ventas.csv`
- **Transformations**:
  - Cast `cantidad` â†’ `int`
  - Cast `precio_unitario` â†’ `double`
  - Compute `total_venta = cantidad Ã— precio_unitario`
  - Filter invalid rows
- **Output**: `s3://data-cgarridolizana/processed/ventas/` as Parquet

## ğŸ“Œ Sample Code

```python
args = getResolvedOptions(sys.argv, ["JOB_NAME"])
job.init(args["JOB_NAME"], args)
df = df.withColumn("total_venta", F.col("cantidad") * F.col("precio_unitario"))
df_clean.write.mode("overwrite").parquet("s3://.../processed/ventas/")
```

## ğŸŒ Next Steps

- Trigger via AWS Lambda (event-driven)
- Orchestrate with Apache Airflow
- Load into Amazon Redshift
- Visualize with Power BI or QuickSight

---

## ğŸ‡ªğŸ‡¸ Pipeline de Procesamiento de Ventas con AWS Glue 5.0

Este proyecto implementa un Job de Glue 5.0 que transforma datos crudos de ventas (en formato CSV en S3) en archivos Parquet estructurados y limpios. Aplica casteo seguro de tipos, validaciÃ³n, cÃ¡lculo de la mÃ©trica derivada `total_venta`, y estÃ¡ preparado para integrarse a un pipeline analÃ­tico moderno.

## ğŸ§± TecnologÃ­as

- AWS Glue 5.0 (Spark 3.5, Python 3.11)
- Amazon S3
- PySpark
- Parquet optimizado
- Compatible con Lambda, Airflow y Redshift

## âš™ï¸ LÃ³gica del ETL

- **Entrada**: `s3://data-cgarridolizana/raw/ventas.csv`
- **Transformaciones**:
  - Cast `cantidad` â†’ `int`
  - Cast `precio_unitario` â†’ `double`
  - CÃ¡lculo: `total_venta = cantidad Ã— precio_unitario`
  - Filtro de registros invÃ¡lidos
- **Salida**: `s3://data-cgarridolizana/processed/ventas/` en Parquet

## ğŸ“Œ Fragmento de CÃ³digo

```python
args = getResolvedOptions(sys.argv, ["JOB_NAME"])
job.init(args["JOB_NAME"], args)
df = df.withColumn("total_venta", F.col("cantidad") * F.col("precio_unitario"))
df_clean.write.mode("overwrite").parquet("s3://.../processed/ventas/")
```

## ğŸŒ PrÃ³ximos pasos

- Activador automÃ¡tico con AWS Lambda  
- OrquestaciÃ³n con Apache Airflow  
- Carga a Redshift para anÃ¡lisis  
- VisualizaciÃ³n con Power BI o QuickSight
 â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹   â€‹
