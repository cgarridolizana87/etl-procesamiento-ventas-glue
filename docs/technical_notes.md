# ğŸ“„ Technical Notes - ETL with AWS Glue 5.0

## âœ… Key Job Parameters
- Glue Version: 5.0 (Spark 3.5, Python 3.11)
- Output format: Parquet
- Write mode: `overwrite`
- Validation: `dropna` on critical columns

## ğŸ§ª Transformations Applied
- Type casting:
  - `cantidad` â†’ Integer
  - `precio_unitario` â†’ Double
- Business logic:
  - `total_venta = cantidad * precio_unitario`
- Data cleaning:
  - Dropping null rows in critical columns

## ğŸ› ï¸ Best Practices Implemented
- Explicit schema enforcement (type safety)
- Raw vs. Processed S3 separation
- Column transformations documented for reproducibility

## ğŸªµ Common Issues Resolved
- Spark type mismatches (cast errors)
- Null fields causing Py4J exceptions
- Region mismatch during S3 writing

## ğŸ“‚ File Paths
- Raw zone: `s3://data-cgarridolizana/raw/ventas.csv`
- Processed zone: `s3://data-cgarridolizana/processed/ventas/`